{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "Task 7- Stock-Market-Prediction-using-Numerical-and-Textual-Analysis.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YogeshBarude/Prediction-using-Supervised-ML/blob/main/Task-7_Stock_Market_Prediction_using_Numerical_and_Textual_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGOh1VgIM3Ul"
      },
      "source": [
        "# GRIP internship "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWtIcbiFM3Uo"
      },
      "source": [
        "## Task7 : #7 STOCK MARKET PREDICTION USING NUMERICAL AND TEXTUAL ANALYSIS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtrqEEp1M3Up"
      },
      "source": [
        "### Task :\n",
        "* Create a hybrid model for stock price/performance prediction using numerical analysis of historical stock prices, and   sentimental analysis of news headlines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6YM_4cnM3Up"
      },
      "source": [
        "# By Yogesh Barude"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyoefZYTM3Uq"
      },
      "source": [
        "* In this I have predicted if a companies stock will increase or decrease based on news headlines using sentiment analysis.\n",
        "\n",
        "* This model will determine if the price of a stock will increase or decrease based on the sentiment of top news article headlines for the current day using Python and machine learning.\n",
        "\n",
        "* I have used both numerical and textual data for this.\n",
        "\n",
        " (i) Time series analysis is performed on the Stock data.\n",
        " \n",
        " (ii) Sentiment analysis is performed on the News data.\n",
        " \n",
        " (iii) An analysis is performed by merging both the data to predict if the Close price of the stock will increase or decrease.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtePhXjzM3Uq"
      },
      "source": [
        "   ## Stock Market Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUhUdKiSM3Uq",
        "outputId": "1fb00f4f-5d4a-4396-e46d-71003586f1c2"
      },
      "source": [
        "!pip install pandas-datareader\n",
        "!pip install pmdarima\n",
        "! pip install textBlob\n",
        "! pip install vaderSentiment"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas-datareader in /usr/local/lib/python3.7/dist-packages (0.9.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from pandas-datareader) (4.2.6)\n",
            "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.7/dist-packages (from pandas-datareader) (1.1.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pandas-datareader) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23->pandas-datareader) (1.19.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23->pandas-datareader) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23->pandas-datareader) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.23->pandas-datareader) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pandas-datareader) (3.0.4)\n",
            "Collecting pmdarima\n",
            "  Downloading pmdarima-1.8.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.7/dist-packages (from pmdarima) (1.1.5)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from pmdarima) (1.24.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from pmdarima) (1.0.1)\n",
            "Requirement already satisfied: setuptools!=50.0.0,>=38.6.0 in /usr/local/lib/python3.7/dist-packages (from pmdarima) (57.4.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.7/dist-packages (from pmdarima) (1.4.1)\n",
            "Collecting statsmodels!=0.12.0,>=0.11\n",
            "  Downloading statsmodels-0.13.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.8 MB 40.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Cython!=0.29.18,>=0.29 in /usr/local/lib/python3.7/dist-packages (from pmdarima) (0.29.24)\n",
            "Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.7/dist-packages (from pmdarima) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.7/dist-packages (from pmdarima) (0.22.2.post1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19->pmdarima) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19->pmdarima) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.19->pmdarima) (1.15.0)\n",
            "Collecting patsy>=0.5.2\n",
            "  Downloading patsy-0.5.2-py2.py3-none-any.whl (233 kB)\n",
            "\u001b[K     |████████████████████████████████| 233 kB 67.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: patsy, statsmodels, pmdarima\n",
            "  Attempting uninstall: patsy\n",
            "    Found existing installation: patsy 0.5.1\n",
            "    Uninstalling patsy-0.5.1:\n",
            "      Successfully uninstalled patsy-0.5.1\n",
            "  Attempting uninstall: statsmodels\n",
            "    Found existing installation: statsmodels 0.10.2\n",
            "    Uninstalling statsmodels-0.10.2:\n",
            "      Successfully uninstalled statsmodels-0.10.2\n",
            "Successfully installed patsy-0.5.2 pmdarima-1.8.3 statsmodels-0.13.0\n",
            "Requirement already satisfied: textBlob in /usr/local/lib/python3.7/dist-packages (0.15.3)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.7/dist-packages (from textBlob) (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textBlob) (1.15.0)\n",
            "Collecting vaderSentiment\n",
            "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from vaderSentiment) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (2.10)\n",
            "Installing collected packages: vaderSentiment\n",
            "Successfully installed vaderSentiment-3.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFlj6nHwM3Us"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pylab as pl\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import datetime\n",
        "import pandas_datareader.data as web\n",
        "import matplotlib as mpl\n",
        "from matplotlib import style\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from statsmodels.tsa.stattools import adfuller, acf, pacf\n",
        "from statsmodels.tsa.arima_model import ARIMA\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error,r2_score\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "\n",
        "\n",
        "from textblob import TextBlob\n",
        "from matplotlib.pyplot import figure\n",
        "from matplotlib import rcParams\n",
        "import plotly.express as px\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import nltk\n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
        "import xgboost \n",
        "import lightgbm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdW-RSpBM3Ut"
      },
      "source": [
        "## Importing stocks data from web"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylzRE795M3Uu"
      },
      "source": [
        "start = datetime.datetime(2010, 1, 1)\n",
        "end = datetime.datetime.today()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "id": "7C2GGmLxM3Uu",
        "outputId": "e12b0c9d-cf3e-40f3-92a2-d05a5cd874b3"
      },
      "source": [
        "stocks = web.DataReader(\"AAPL\", 'yahoo', start, end)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RemoteDataError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRemoteDataError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-8a96a1cd104e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"AAPL\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'yahoo'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas_datareader/data.py\u001b[0m in \u001b[0;36mDataReader\u001b[0;34m(name, data_source, start, end, retry_count, pause, session, api_key)\u001b[0m\n\u001b[1;32m    382\u001b[0m             \u001b[0mretry_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0mpause\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         ).read()\n\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas_datareader/base.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;31m# If a single symbol, (e.g., 'GOOG')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m             \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_one_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0;31m# Or multiple symbols, (e.g., ['GOOG', 'AAPL', 'MSFT'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymbols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas_datareader/yahoo/daily.py\u001b[0m in \u001b[0;36m_read_one_data\u001b[0;34m(self, url, params)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0mptrn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mr\"root\\.App\\.main = (.*?);\\n}\\(this\\)\\);\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas_datareader/base.py\u001b[0m in \u001b[0;36m_get_response\u001b[0;34m(self, url, params, headers)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"\\nResponse Text:\\n{0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_response_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRemoteDataError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_crumb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRemoteDataError\u001b[0m: Unable to read URL: https://finance.yahoo.com/quote/AAPL/history?period1=1262318400&period2=1633406399&interval=1d&frequency=1d&filter=history\nResponse Text:\nb'<!DOCTYPE html>\\n  <html lang=\"en-us\"><head>\\n  <meta http-equiv=\"content-type\" content=\"text/html; charset=UTF-8\">\\n      <meta charset=\"utf-8\">\\n      <title>Yahoo</title>\\n      <meta name=\"viewport\" content=\"width=device-width,initial-scale=1,minimal-ui\">\\n      <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge,chrome=1\">\\n      <style>\\n  html {\\n      height: 100%;\\n  }\\n  body {\\n      background: #fafafc url(https://s.yimg.com/nn/img/sad-panda-201402200631.png) 50% 50%;\\n      background-size: cover;\\n      height: 100%;\\n      text-align: center;\\n      font: 300 18px \"helvetica neue\", helvetica, verdana, tahoma, arial, sans-serif;\\n  }\\n  table {\\n      height: 100%;\\n      width: 100%;\\n      table-layout: fixed;\\n      border-collapse: collapse;\\n      border-spacing: 0;\\n      border: none;\\n  }\\n  h1 {\\n      font-size: 42px;\\n      font-weight: 400;\\n      color: #400090;\\n  }\\n  p {\\n      color: #1A1A1A;\\n  }\\n  #message-1 {\\n      font-weight: bold;\\n      margin: 0;\\n  }\\n  #message-2 {\\n      display: inline-block;\\n      *display: inline;\\n      zoom: 1;\\n      max-width: 17em;\\n      _width: 17em;\\n  }\\n      </style>\\n  <script>\\n    document.write(\\'<img src=\"//geo.yahoo.com/b?s=1197757129&t=\\'+new Date().getTime()+\\'&src=aws&err_url=\\'+encodeURIComponent(document.URL)+\\'&err=%<pssc>&test=\\'+encodeURIComponent(\\'%<{Bucket}cqh[:200]>\\')+\\'\" width=\"0px\" height=\"0px\"/>\\');var beacon = new Image();beacon.src=\"//bcn.fp.yahoo.com/p?s=1197757129&t=\"+ne..."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTGv4sLzM3Uu"
      },
      "source": [
        "stocks.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6CBiXlVM3Uv"
      },
      "source": [
        "stocks.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heyJEpj6M3Uv"
      },
      "source": [
        "stocks.reset_index(inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmnfwpxmM3Uv"
      },
      "source": [
        "stocks.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UiUQ4rTM3Uv"
      },
      "source": [
        "stocks.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSBbfA7uM3Uw"
      },
      "source": [
        "stocks.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4M6rS7KM3Uw"
      },
      "source": [
        "### Data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUxEM8lsM3Uw"
      },
      "source": [
        "stocks['Date'] = pd.to_datetime(stocks['Date'])\n",
        "stocks.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJYIZGPcM3Uw"
      },
      "source": [
        "### Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikz7At-BM3Ux"
      },
      "source": [
        "stocks.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fV9CJkA3M3Ux"
      },
      "source": [
        "### Visualizing the data -Close Price"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nY5boXLzM3Ux"
      },
      "source": [
        "plt.figure(figsize=(5,5))\n",
        "plt.title('Closing Price of Stocks', fontsize = 18)\n",
        "plt.xlabel('Days', fontsize= 18)\n",
        "plt.ylabel('Close', fontsize = 18)\n",
        "plt.plot(stocks['Close'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzKMEMaXM3Uy"
      },
      "source": [
        "### Visualizing the data -Open Price"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfaiUCnoM3Uy"
      },
      "source": [
        "plt.figure(figsize=(5,5))\n",
        "plt.grid(True)\n",
        "plt.plot(stocks['Open'])\n",
        "plt.xlabel('Days')\n",
        "plt.ylabel('Open Price')\n",
        "plt.title('Opening price of Stocks')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-0wrRpDM3Uy"
      },
      "source": [
        "### Visualising Stocks returns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuHuPn0sM3Uy"
      },
      "source": [
        "close = stocks['Close']\n",
        "returns = close / close.shift(1) - 1\n",
        "\n",
        "plt.figure(figsize = (10,6))\n",
        "returns.plot(label='Return', color = 'g')\n",
        "plt.title(\"Stock Returns\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3EHYd43M3Uy"
      },
      "source": [
        "## Time series Analysis -For Close Price\n",
        "We can also perform the same analysis for Open price as well"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOYEAbNhM3Uy"
      },
      "source": [
        "   Time series decomposition involves thinking of a series as a combination of level, trend, seasonality, and noise components.\n",
        " we need to separate seasonality and trend from our series. The resultant series will become stationary through this process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUKk9TtpM3Uz"
      },
      "source": [
        "### Splitting data into train and test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2Vbfu_iM3Uz"
      },
      "source": [
        "train = stocks[:1600]\n",
        "test = stocks[1600:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3h4L1VgM3Uz"
      },
      "source": [
        "train.shape, test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VcLUWfHM3Uz"
      },
      "source": [
        "### Decomposition of Time series"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEKvwiH6M3Uz"
      },
      "source": [
        "### Stationarity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLs54L_CM3Uz"
      },
      "source": [
        "A stationary process has a mean and variance that do not change overtime and the process does not have trend.\n",
        "\n",
        "The above time series does not look stationary.\n",
        "\n",
        "To confirm that we will use “Dickey-Fuller test” to determine stationarity.\n",
        "\n",
        "Dickey-Fuller test for variable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbYITNqHM3U0"
      },
      "source": [
        "### Dickey-Fuller test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYPXdLoZM3U0"
      },
      "source": [
        "def adfullerTest(X):\n",
        "    result = adfuller(X,autolag = 'AIC')\n",
        "    print('ADF Statistic: %f' % result[0])\n",
        "    print('p-value: %f' % result[1])\n",
        "    print('No of Lags Used: %f' % result[2])\n",
        "    print('Number of Obs Used: %f' % result[3])\n",
        "    print('Critical Values:')\n",
        "    for key, value in result[4].items():\n",
        "        print('\\t%s: %.3f' % (key, value))\n",
        "    if result[1] <=0.05 :\n",
        "         print(\"Reject against the null hypothesis, time series is stationary\")\n",
        "    else:\n",
        "        print(\"Accept null hypothesis, time series is non-stationary \") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_0Nvbe5M3U0"
      },
      "source": [
        "adfullerTest(train['Close'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2IxPgGaM3U0"
      },
      "source": [
        "We can see that our statistic value of -1.4 is greater than the value of -3.437 at 1% critical value.\n",
        "   By Comparing the test statistic to the critical values, it looks like we would have to fail to reject the null hypothesis that the time series is non-stationary and does have time-dependent structure."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b15ll6TCM3U0"
      },
      "source": [
        "##### Rolling Statistics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1kyt0-BM3U0"
      },
      "source": [
        "rolling_mean_50 = (train['Close']).rolling(window=50).mean()\n",
        "rolling_std_50 = (train['Close']).rolling(window=50).std()\n",
        "plt.figure(figsize = (8,8))\n",
        "plt.plot((train['Close']), color = 'blue', label = 'original')\n",
        "plt.plot(rolling_mean_50, color = 'red', label = 'rolling mean 50')\n",
        "plt.plot(rolling_std_50, color = 'black', label = 'rolling std 50')\n",
        "plt.xlabel('Time')\n",
        "plt.legend()\n",
        "plt.title('Mean and Standard Deviation on  transformed data',  fontsize = 20)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OupRLFGwM3U1"
      },
      "source": [
        "Since the data shows changing variance over time, the first thing we will do is stabilize the variance by applying log transformation using the log() function. The resulting series will be a linear time series."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2C6ZvRUM3U1"
      },
      "source": [
        "### Log Transfromation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jM0C1J-M3U1"
      },
      "source": [
        "Let’s log transform the dataset again to make the distribution of values more linear and better meet the expectations of this statistical test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSfqNxifM3U1"
      },
      "source": [
        "train_log = np.log(train['Close']) \n",
        "test_log = np.log(test['Close'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAi-E4xAM3U1"
      },
      "source": [
        "from numpy import log\n",
        "adfullerTest(log(train['Close']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iz8fdwhM3U1"
      },
      "source": [
        "Running this shows a negative value for the test statistic.\n",
        "\n",
        "We can see that the value is larger than the critical values, again, meaning that we can fail to reject the null hypothesis and in turn that the time series is non-stationary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4g6P-TOkM3U1"
      },
      "source": [
        "rolling_mean_50 = log(train['Close']).rolling(window=50).mean()\n",
        "rolling_std_50 = log(train['Close']).rolling(window=50).std()\n",
        "plt.figure(figsize = (8,8))\n",
        "plt.plot(log(train['Close']), color = 'g', label = 'Log Transformed')\n",
        "plt.plot(rolling_mean_50, color = 'r', label = 'rolling mean 50')\n",
        "plt.plot(rolling_std_50, color = 'r', label = 'rolling std 50')\n",
        "plt.xlabel('Time')\n",
        "plt.legend()\n",
        "plt.title('Mean and Standard Deviation on Log transformed data',  fontsize = 20)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-_wLZTrM3U2"
      },
      "source": [
        "##### To Removing Linear Trend"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z336gNQlM3U2"
      },
      "source": [
        "###### We will now perform the first difference transformation to our series to remove the linear trend."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TT1PQi8pM3U2"
      },
      "source": [
        "mean_log = log(train['Close']).rolling(50).mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51BpOo7XM3U2"
      },
      "source": [
        "train_log_diff = log(train['Close']) - mean_log\n",
        "train_log_diff.dropna(inplace = True)\n",
        "adfullerTest(train_log_diff)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdDFXKPhM3U2"
      },
      "source": [
        "data=   train_log_diff\n",
        "mean = data.rolling(50).mean()\n",
        "std = data.rolling(50).std()\n",
        "plt.figure(figsize = (8,8))\n",
        "plt.plot(data, color = 'g', label = 'Differential Log Transformed data')\n",
        "plt.plot(mean, color = 'r', label = 'rolling mean')\n",
        "plt.plot(std, color = 'b', label = 'rolling std')\n",
        "plt.xlabel('Time')\n",
        "plt.legend()\n",
        "plt.title('Mean and Standard Deviation on Differential Log Transformed data',  fontsize = 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjW7fzQiM3U2"
      },
      "source": [
        "Rejecting the null hypothesis means that the process has no unit root, and in turn that the time series is stationary or does not have time-dependent structure.\n",
        "Here we can also observe that there is no such trend in mean and Standard deviation\n",
        "So the now time series is statinary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fs3wZWa_M3U2"
      },
      "source": [
        "Now the data is stationary we can apply ARIMA model to our data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nneoXf7IM3U3"
      },
      "source": [
        "### ARIMA Model "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oBvKlYmM3U3"
      },
      "source": [
        "    AR: Autoregression. A model that uses the dependent relationship between an observation and some number of lagged observations.\n",
        "    I: Integrated. The use of differencing of raw observations (e.g. subtracting an observation from an observation at the previous time step) in order to make the time series stationary.\n",
        "    MA: Moving Average. A model that uses the dependency between an observation and a residual error from a moving average model applied to lagged observations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fV4UVR7mM3U3"
      },
      "source": [
        "The parameters of the ARIMA model are defined as follows:\n",
        "\n",
        "    p: The number of lag observations included in the model, also called the lag order.\n",
        "    d: The number of times that the raw observations are differenced, also called the degree of differencing.\n",
        "    q: The size of the moving average window, also called the order of moving average."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwztDcLoM3U3"
      },
      "source": [
        "import pmdarima as pmd\n",
        "\n",
        "def arimamodel(timeseriesarray):\n",
        "    autoarima_model = pmd.auto_arima(timeseriesarray, \n",
        "                             # start_p=1, \n",
        "                              #start_q=1,\n",
        "                              #test=\"adf\",\n",
        "                              trace=True,\n",
        "                              error_action = 'ignore',\n",
        "                              suppress_warnings = True)\n",
        "    return autoarima_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMWC5y8kM3U3"
      },
      "source": [
        "stocks_arima = arimamodel((train_log))\n",
        "stocks_arima.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AfwpGobLM3U3"
      },
      "source": [
        "stocks_arima.plot_diagnostics(figsize=(10,10))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4r8g8KiWM3U3"
      },
      "source": [
        "### Predictions on test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_d21ivMM3U3"
      },
      "source": [
        "predict_ClosePrice = stocks_arima.predict(n_periods = len(test_log))\n",
        "predict_ClosePrice = pd.DataFrame(predict_ClosePrice,index = test_log.index,columns=['predict_ClosePrice'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbJ20QHJM3U4"
      },
      "source": [
        "plt.plot(train_log, label='Train')\n",
        "plt.plot(test_log, label='Test')\n",
        "plt.plot(predict_ClosePrice, label='Prediction')\n",
        "plt.title(' Stock Price Prediction')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Actual Stock Price')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9QwABo4M3U4"
      },
      "source": [
        "### Validation of the Arima Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdLKSpAsM3U4"
      },
      "source": [
        "print('Mean Squared Error      ',mean_squared_error(test_log, predict_ClosePrice))\n",
        "print('Root Mean_Squared_Error ',np.sqrt(mean_squared_error(test_log, predict_ClosePrice)))\n",
        "print('Mean Absolute Error     ',mean_absolute_error(test_log, predict_ClosePrice))\n",
        "print('R-Squared               ',r2_score(test_log, predict_ClosePrice))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9GQ2aFjM3U4"
      },
      "source": [
        "## Analyzing  news dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pN8iab4vM3U4"
      },
      "source": [
        "news=pd.read_csv(\"C:\\\\Users\\\\Keerthi\\\\Desktop\\\\04-Keerthi\\\\00-Spark Foundation\\\\Stocks\\\\india-news-headlines.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HcxAG91M3U4"
      },
      "source": [
        "news.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0HO_izZM3U4"
      },
      "source": [
        "news['publish_date'] = pd.to_datetime(news['publish_date'],format= '%Y%m%d')\n",
        "news.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psstjzy1M3U4"
      },
      "source": [
        "news.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3aY7Rxv0M3U5"
      },
      "source": [
        "news.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTzdA1sWM3U5"
      },
      "source": [
        "(news.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuvUF7wSM3U5"
      },
      "source": [
        "### Analaysing \"HEADLINE_CATEGORY\" with \"CITIES\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zwsq9IilM3U5"
      },
      "source": [
        "news['headline_category'].value_counts().head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7j8IgL4M3U5"
      },
      "source": [
        "cities = news[news['headline_category'].str.contains('^city\\.[a-z]+$', regex=True)]\n",
        "cities.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05HZblPNM3U5"
      },
      "source": [
        "city = pd.DataFrame(columns = ['city_name'])\n",
        "city['city_name'] = cities.headline_category.str.split('.',expand = True)[1]\n",
        "cities = pd.concat([cities, city], axis = 1)\n",
        "cities.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9kSVL-RM3U5"
      },
      "source": [
        "cities.drop('headline_category', inplace =True,axis =1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lj5ZrTuAM3U6"
      },
      "source": [
        "cities.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeZl_ATBM3U6"
      },
      "source": [
        "cites = cities.groupby(cities['city_name']).agg({'headline_text':'count'})\n",
        "cites.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FP8xg10hM3U6"
      },
      "source": [
        "cites.rename(columns = {'headline_text':'headline_count'}, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GI6CbeIXM3U6"
      },
      "source": [
        "cites = cites.sort_values(by='headline_count',ascending=False)\n",
        "cites.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sl8zp6tbM3U6"
      },
      "source": [
        "top10cites = cites.head(10)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aY4mI073M3U6"
      },
      "source": [
        "def fig_plot(top10cites,title1):\n",
        "    fig = px.line(top10cites,title =title1)\n",
        "    for i in top10cites.columns[0:]:\n",
        "        fig.add_bar(x= top10cites.index ,y = top10cites['headline_count'],name = i)\n",
        "    fig.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnMG96qnM3U6"
      },
      "source": [
        "fig_plot(top10cites,'Count of Headlines for top10 Cities')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPgVp92NM3U6"
      },
      "source": [
        "cities.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rihprrfIM3U7"
      },
      "source": [
        "### Analaysing \"HEADLINE_CATEGORY\" with \"CATEGORIES\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKi7itiWM3U7"
      },
      "source": [
        "news.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XM-Fs8DcM3U7"
      },
      "source": [
        "news['category']=news['headline_category'].str.split('.').map(lambda x : x[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHDjo6YFM3U7"
      },
      "source": [
        "categories = news.groupby(['category']).agg({'headline_text':'count'}).sort_values(by='headline_text',ascending = False)\n",
        "news_cat=categories.head(10)\n",
        "news_cat.reset_index(inplace = True)\n",
        "news_cat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQ0dR01vM3U7"
      },
      "source": [
        "import matplotlib.colors as mcolors\n",
        "plt.figure(figsize=(17,5))\n",
        "plt.bar(news_cat.category,height= news_cat.headline_text, color = 'c')\n",
        "plt.xlabel('Category')\n",
        "plt.ylabel('Number of articles')\n",
        "plt.title('Top 10 Categories')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWR0DTlBM3U7"
      },
      "source": [
        "news.drop('headline_category', inplace  = True, axis =1)\n",
        "news.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSrlpV_qM3U7"
      },
      "source": [
        "### Cleaning the data -Removing Stop words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTIvprFBM3U7"
      },
      "source": [
        "headline_text = ' '.join(news['headline_text'].str.lower())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axO5i0rRM3U8"
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lyJWA7IM3U8"
      },
      "source": [
        "wordcloud = WordCloud(stopwords=stop_words, background_color=\"white\", max_words=1000).generate(headline_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "wvbqHlo2M3U8"
      },
      "source": [
        "rcParams['figure.figsize'] = 10, 10\n",
        "plt.imshow(wordcloud)\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCWuTcyvM3U8"
      },
      "source": [
        "### Sentimental Analaysis -- Assigning Polarity to the Headlines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqnyzS6BM3U8"
      },
      "source": [
        "# Create a function to get the subjectivity\n",
        "def Subjectivity(text):\n",
        "       return TextBlob(text).sentiment.subjectivity\n",
        "\n",
        "# Create a function to get the polarity\n",
        "def Polarity(text):\n",
        "      return  TextBlob(text).sentiment.polarity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxEPheSgM3U8"
      },
      "source": [
        "news['Subjectivity'] =news['headline_text'].apply(Subjectivity)\n",
        "news['Polarity'] =news['headline_text'].apply(Polarity)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jtQZuO6M3U8"
      },
      "source": [
        "import nltk\n",
        "\n",
        "senti = SentimentIntensityAnalyzer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzFlC49hM3U9"
      },
      "source": [
        "news['Compound'] = [senti.polarity_scores(s)['compound'] for s in news['headline_text']]\n",
        "news['Negative'] = [senti.polarity_scores(s)['neg'] for s in news['headline_text']]\n",
        "news['Neutral'] = [senti.polarity_scores(s)['neu'] for s in news['headline_text']]\n",
        "news['Positive'] = [senti.polarity_scores(s)['pos'] for s in news['headline_text']]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eMvlO1iM3U9"
      },
      "source": [
        "news.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-wTjT54M3U-"
      },
      "source": [
        "## Hybrid model - Combining Stocks data and news data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfaFnWlTM3U-"
      },
      "source": [
        "news.rename(columns = {'publish_date':'Date'}, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5IAafkWM3U_"
      },
      "source": [
        "df_merge = pd.merge(stocks, news, how='inner', on=['Date'])\n",
        "df_merge.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "nJsaUIzxM3U_"
      },
      "source": [
        "df = df_merge[['Close','Subjectivity', 'Polarity', 'Compound', 'Negative', 'Neutral' ,'Positive']]\n",
        "df.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CP-o1_DcM3U_"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "sc = MinMaxScaler()\n",
        "new_df = pd.DataFrame(sc.fit_transform(df))\n",
        "new_df.columns = df.columns\n",
        "new_df.index = df.index\n",
        "new_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vihWQzLzM3U_"
      },
      "source": [
        "### Spliting Data into Train and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9jMpzIgM3U_"
      },
      "source": [
        "X = new_df.drop('Close', axis=1)\n",
        "y =new_df['Close']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SnomGdiM3U_"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2, random_state = 0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYdI5X7OM3U_"
      },
      "source": [
        "X_train.shape , X_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReUBYQxzM3VA"
      },
      "source": [
        "def func_graph(results,names):\n",
        "    fig = plt.figure()\n",
        "    fig.suptitle('MSE value of all Algorithms Comparison')\n",
        "    ax = fig.add_subplot(111)\n",
        "    width = 0.5        \n",
        "    bars=plt.bar(names,results, width, align='center')\n",
        "    ax.set_xticklabels(names)\n",
        "    for bar in bars:\n",
        "        yval = bar.get_height()\n",
        "        plt.text(bar.get_x(), yval +0.005, yval)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CE-qndzfM3VA"
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "def metric_calc(name,model,category, X_train, Y_train, X_test, Y_test):\n",
        "    if category =='TRAINING DATA' :\n",
        "        X_data= X_train\n",
        "        Y_data=Y_train\n",
        "    else :\n",
        "        X_data= X_test\n",
        "        Y_data=Y_test\n",
        "        \n",
        "    model.fit(X_train, Y_train)\n",
        "    predictions = model.predict(X_data)\n",
        "    mse =round(metrics.mean_squared_error(predictions,Y_data),4)   \n",
        "    print('For ', name, 'MSE-Value is ', mse)\n",
        "    return mse\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aoTCSJHM3VA"
      },
      "source": [
        "def func_modelling(i) :\n",
        "    count=0\n",
        "    count=count+1\n",
        "    X = X_train[i]\n",
        "    Y = Y_train\n",
        "    x_test = X_test[i]\n",
        "    seed = 7\n",
        "    # preparing models list\n",
        "    models = []\n",
        "    models.append(('Decision Tree',' DecisiontreeRegressor  ', DecisionTreeRegressor()))\n",
        "    models.append(('Random Forest',' RandomForestRegressor  ', RandomForestRegressor()))\n",
        "    models.append(('XG Boost',' XGBRegressor  ', xgboost.XGBRegressor()))\n",
        "    models.append(('LG Boost',' LGBMRegressor ', lightgbm.LGBMRegressor()))\n",
        "    models.append(('ADA Boost',' AdaBoostRegressor ', AdaBoostRegressor()))\n",
        "    results_train = []\n",
        "    results_test = []\n",
        "    names = []\n",
        "    scoring = 'MSE'\n",
        "\n",
        "    print('Metrics calcuated while TRANING the model')\n",
        "    for name,label, model in models:\n",
        "            cv_results_train=metric_calc(name,model,'TRAINING DATA',X,Y, x_test,Y_test)\n",
        "            results_train.append(cv_results_train)\n",
        "            names.append(name)\n",
        "    func_graph(results_train,names)\n",
        "    \n",
        "    print('Evaluating the model on TESTING DATA')\n",
        "    for name,label, model in models:\n",
        "            cv_results_test=metric_calc(name,model,'TESTING DATA',X,Y, x_test,Y_test)\n",
        "            results_test.append(cv_results_test)\n",
        "            #names.append(name)\n",
        "    func_graph(results_test,names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFgoV18XM3VA"
      },
      "source": [
        "### Training the model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaCV4aOsM3VA"
      },
      "source": [
        "func_modelling(X_train.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDdNO18qM3VA"
      },
      "source": [
        "LGBMRegressor has the least MSE and it has performed best for sentimental Anaylsis to predict if the stock close price with either increase or decrease depending on the news on that day."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZftLjaaVM3VA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}